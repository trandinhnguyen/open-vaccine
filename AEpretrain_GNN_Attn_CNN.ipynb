{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_dir = None # model dir for resuming training. if None, train from scrach\n",
    "\n",
    "one_fold = False # if True, train model at only first fold. use if you try a new idea quickly.\n",
    "run_test = False # if True, use small data. you can check whether this code run or not\n",
    "denoise = True # if True, use train data whose signal_to_noise > 1\n",
    "\n",
    "ae_epochs = 10 # epoch of training of denoising auto encoder\n",
    "ae_epochs_each = 5 # epoch of training of denoising auto encoder each time. \n",
    "                   # I use train data (seqlen = 107) and private test data (seqlen = 130) for auto encoder training.\n",
    "                   # I dont know how to easily fit keras model to use both of different shape data simultaneously, \n",
    "                   # so I call fit function several times. \n",
    "ae_batch_size = 32\n",
    "\n",
    "# epochs_list = [30, 10] # 3, 3, 5, 5]\n",
    "epochs_list = [10]\n",
    "batch_size_list = [8, 16] #32, 64, 128, 256] \n",
    "\n",
    "## copy pretrain model to working dir\n",
    "import shutil\n",
    "import glob\n",
    "if pretrain_dir is not None:\n",
    "    for d in glob.glob(pretrain_dir + \"*\"):\n",
    "        shutil.copy(d, \".\")\n",
    "    \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "train = pd.read_json(\"datasets/input/train.json\", lines=True)\n",
    "if denoise:\n",
    "    train = train[train.signal_to_noise > 1].reset_index(drop=True)\n",
    "\n",
    "test = pd.read_json(\"datasets/input/test.json\", lines=True)\n",
    "test_pub = test[test[\"seq_length\"] == 107]\n",
    "test_pri = test[test[\"seq_length\"] == 130]\n",
    "# sub = pd.read_csv(\"datasets/input/sample_submission.csv\")\n",
    "# sub = sub.iloc[:3]\n",
    "\n",
    "if run_test:  ## to test\n",
    "    train = train[:30]\n",
    "    test_pub = test_pub[:30]\n",
    "    test_pri = test_pri[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2096/2096 [00:01<00:00, 1926.64it/s]\n",
      "100%|██████████| 629/629 [00:00<00:00, 1915.41it/s]\n",
      "100%|██████████| 3005/3005 [00:02<00:00, 1491.33it/s]\n"
     ]
    }
   ],
   "source": [
    "bpps = []\n",
    "for id in tqdm(train[\"id\"]):\n",
    "    a = np.load(f\"datasets/input/bpps/{id}.npy\")\n",
    "    bpps.append(a)\n",
    "\n",
    "bpps = np.array(bpps)\n",
    "\n",
    "bpps_pub = []\n",
    "for id in tqdm(test_pub[\"id\"]):\n",
    "    a = np.load(f\"datasets/input/bpps/{id}.npy\")\n",
    "    bpps_pub.append(a)\n",
    "\n",
    "bpps_pub = np.array(bpps_pub)\n",
    "\n",
    "bpps_pri = []\n",
    "for id in tqdm(test_pri[\"id\"]):\n",
    "    a = np.load(f\"datasets/input/bpps/{id}.npy\")\n",
    "    bpps_pri.append(a)\n",
    "\n",
    "bpps_pri = np.array(bpps_pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 107, 107)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2096, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "      <th>reactivity_error</th>\n",
       "      <th>deg_error_Mg_pH10</th>\n",
       "      <th>deg_error_pH10</th>\n",
       "      <th>deg_error_Mg_50C</th>\n",
       "      <th>deg_error_50C</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_001f94081</td>\n",
       "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
       "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
       "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
       "      <td>6.894</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
       "      <td>[0.26130000000000003, 0.38420000000000004, 0.1...</td>\n",
       "      <td>[0.2631, 0.28600000000000003, 0.0964, 0.1574, ...</td>\n",
       "      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n",
       "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
       "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
       "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
       "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
       "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
       "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>id_006f36f57</td>\n",
       "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
       "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
       "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
       "      <td>8.800</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
       "      <td>[0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...</td>\n",
       "      <td>[0.17020000000000002, 0.178, 0.111, 0.091, 0.0...</td>\n",
       "      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n",
       "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
       "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
       "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
       "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
       "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
       "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id                                           sequence  \\\n",
       "0      0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n",
       "1      2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n",
       "\n",
       "                                           structure  \\\n",
       "0  .....((((((.......)))).)).((.....((..((((((......   \n",
       "1  .....((((.((.....((((.(((.....)))..((((......)...   \n",
       "\n",
       "                                 predicted_loop_type  signal_to_noise  \\\n",
       "0  EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n",
       "1  EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n",
       "\n",
       "   SN_filter  seq_length  seq_scored  \\\n",
       "0          1         107          68   \n",
       "1          1         107          68   \n",
       "\n",
       "                                    reactivity_error  \\\n",
       "0  [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...   \n",
       "1  [0.0931, 0.13290000000000002, 0.11280000000000...   \n",
       "\n",
       "                                   deg_error_Mg_pH10  \\\n",
       "0  [0.26130000000000003, 0.38420000000000004, 0.1...   \n",
       "1  [0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...   \n",
       "\n",
       "                                      deg_error_pH10  \\\n",
       "0  [0.2631, 0.28600000000000003, 0.0964, 0.1574, ...   \n",
       "1  [0.17020000000000002, 0.178, 0.111, 0.091, 0.0...   \n",
       "\n",
       "                                    deg_error_Mg_50C  \\\n",
       "0  [0.1501, 0.275, 0.0947, 0.18660000000000002, 0...   \n",
       "1  [0.1033, 0.1464, 0.1126, 0.09620000000000001, ...   \n",
       "\n",
       "                                       deg_error_50C  \\\n",
       "0  [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...   \n",
       "1  [0.14980000000000002, 0.1761, 0.1517, 0.116700...   \n",
       "\n",
       "                                          reactivity  \\\n",
       "0  [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n",
       "1  [0.44820000000000004, 1.4822, 1.1819, 0.743400...   \n",
       "\n",
       "                                         deg_Mg_pH10  \\\n",
       "0  [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n",
       "1  [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n",
       "\n",
       "                                            deg_pH10  \\\n",
       "0  [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n",
       "1  [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n",
       "\n",
       "                                          deg_Mg_50C  \\\n",
       "0  [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n",
       "1  [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n",
       "\n",
       "                                             deg_50C  \n",
       "0  [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...  \n",
       "1  [0.9501000000000001, 1.7974999999999999, 1.499...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3634, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_00073f8be</td>\n",
       "      <td>GGAAAAGUACGACUUGAGUACGGAAAACGUACCAACUCGAUUAAAA...</td>\n",
       "      <td>......((((((((((.(((((.....))))))))((((((((......</td>\n",
       "      <td>EEEEEESSSSSSSSSSBSSSSSHHHHHSSSSSSSSSSSSSSSSHHH...</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>id_000ae4237</td>\n",
       "      <td>GGAAACGGGUUCCGCGGAUUGCUGCUAAUAAGAGUAAUCUCUAAAU...</td>\n",
       "      <td>.....((((..((((((...(((((.....((((....)))).......</td>\n",
       "      <td>EEEEESSSSIISSSSSSIIISSSSSIIIIISSSSHHHHSSSSIIII...</td>\n",
       "      <td>130</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id                                           sequence  \\\n",
       "0      0  id_00073f8be  GGAAAAGUACGACUUGAGUACGGAAAACGUACCAACUCGAUUAAAA...   \n",
       "1      1  id_000ae4237  GGAAACGGGUUCCGCGGAUUGCUGCUAAUAAGAGUAAUCUCUAAAU...   \n",
       "\n",
       "                                           structure  \\\n",
       "0  ......((((((((((.(((((.....))))))))((((((((......   \n",
       "1  .....((((..((((((...(((((.....((((....)))).......   \n",
       "\n",
       "                                 predicted_loop_type  seq_length  seq_scored  \n",
       "0  EEEEEESSSSSSSSSSBSSSSSHHHHHSSSSSSSSSSSSSSSSHHH...         107          68  \n",
       "1  EEEEESSSSIISSSSSSIIISSSSSIIIIISSSSHHHHSSSSIIII...         130          91  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 107, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = [\"reactivity\", \"deg_Mg_pH10\", \"deg_pH10\", \"deg_Mg_50C\", \"deg_50C\"]\n",
    "\n",
    "y_train = []\n",
    "seq_len = train[\"seq_length\"].iloc[0]\n",
    "seq_len_target = train[\"seq_scored\"].iloc[0]\n",
    "ignore = -10000\n",
    "ignore_length = seq_len - seq_len_target\n",
    "\n",
    "for target in targets:\n",
    "    y = np.vstack(train[target])\n",
    "    dummy = np.zeros([y.shape[0], ignore_length]) + ignore\n",
    "    y = np.hstack([y, dummy])\n",
    "    y_train.append(y)\n",
    "\n",
    "y = np.stack(y_train, axis=2)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure adjacent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structure_adj(train):\n",
    "    \"\"\"Get adjacency matrix from structure sequence.\n",
    "    It calculate adjacent matrix of each base pair\n",
    "    but eventually ignore difference of base pair\n",
    "    and intergrate into one matrix\"\"\"\n",
    "\n",
    "    adj_structures = []\n",
    "    for seq_index in tqdm(range(len(train))):\n",
    "        seq_length = train[\"seq_length\"].iloc[seq_index]\n",
    "        structure = train[\"structure\"].iloc[seq_index]\n",
    "        sequence = train[\"sequence\"].iloc[seq_index]\n",
    "\n",
    "        struc_stack = []\n",
    "        adj_structure_dict = {\n",
    "            (\"A\", \"U\"): np.zeros([seq_length, seq_length]),\n",
    "            (\"C\", \"G\"): np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"G\"): np.zeros([seq_length, seq_length]),\n",
    "            (\"U\", \"A\"): np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"C\"): np.zeros([seq_length, seq_length]),\n",
    "            (\"G\", \"U\"): np.zeros([seq_length, seq_length]),\n",
    "        }\n",
    "\n",
    "        # a_structure = np.zeros([seq_length, seq_length])\n",
    "        for i in range(seq_length):\n",
    "            if structure[i] == \"(\":\n",
    "                struc_stack.append(i)\n",
    "            elif structure[i] == \")\":\n",
    "                start = struc_stack.pop()\n",
    "\n",
    "                # a_structure[start, i] = 1\n",
    "                # a_structure[i, start] = 1\n",
    "                adj_structure_dict[(sequence[start], sequence[i])][start, i] = 1\n",
    "                adj_structure_dict[(sequence[i], sequence[start])][i, start] = 1\n",
    "\n",
    "        adj_structure = np.stack([i for i in adj_structure_dict.values()], axis=2)\n",
    "        adj_structure = np.sum(adj_structure, axis=2, keepdims=True)\n",
    "        adj_structures.append(adj_structure)\n",
    "\n",
    "    adj_structures = np.array(adj_structures)\n",
    "    print(adj_structures.shape)\n",
    "    return adj_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2096/2096 [00:00<00:00, 4481.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2096, 107, 107, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 629/629 [00:00<00:00, 4352.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(629, 107, 107, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3005/3005 [00:01<00:00, 2911.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3005, 130, 130, 1)\n"
     ]
    }
   ],
   "source": [
    "adj_struc = get_structure_adj(train)\n",
    "adj_struc_pub = get_structure_adj(test_pub)\n",
    "adj_struc_pri = get_structure_adj(test_pri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance adjacent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(bpps):\n",
    "    \"\"\"Adjacent matrix based on distance on the sequence.\n",
    "    D[i, j] = 1 / (abs(i - j) + 1) ** pow, pow = 1, 2, 4\"\"\"\n",
    "    idx = np.arange(bpps.shape[1])\n",
    "\n",
    "    distance_seq = [np.abs(idx[i] - idx) for i in range(len(idx))]\n",
    "    distance_seq = np.array(distance_seq) + 1\n",
    "    distance_seq = 1 / distance_seq\n",
    "\n",
    "    distance_seq = distance_seq[None, :, :]\n",
    "    distance_seq = np.repeat(distance_seq, bpps.shape[0], axis=0)\n",
    "\n",
    "    distance_powered = [distance_seq**pow for pow in [1, 2, 4]]\n",
    "    distance_seq = np.stack(distance_powered, axis=3)\n",
    "\n",
    "    print(distance_seq.shape)\n",
    "    return distance_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2096, 107, 107, 3)\n",
      "(629, 107, 107, 3)\n",
      "(3005, 130, 130, 3)\n"
     ]
    }
   ],
   "source": [
    "distance_matrix = get_distance_matrix(bpps)\n",
    "distance_matrix_pub = get_distance_matrix(bpps_pub)\n",
    "distance_matrix_pri = get_distance_matrix(bpps_pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2096, 107, 107, 5), (629, 107, 107, 5), (3005, 130, 130, 5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat adjacent\n",
    "adjacents = np.concatenate(\n",
    "    [bpps[:, :, :, None], adj_struc, distance_matrix], axis=3\n",
    ").astype(np.float32)\n",
    "del bpps, adj_struc, distance_matrix\n",
    "\n",
    "adjacents_pub = np.concatenate(\n",
    "    [bpps_pub[:, :, :, None], adj_struc_pub, distance_matrix_pub], axis=3\n",
    ").astype(np.float32)\n",
    "del bpps_pub, adj_struc_pub, distance_matrix_pub\n",
    "\n",
    "adjacents_pri = np.concatenate(\n",
    "    [bpps_pri[:, :, :, None], adj_struc_pri, distance_matrix_pri], axis=3\n",
    ").astype(np.float32)\n",
    "del bpps_pri, adj_struc_pri, distance_matrix_pri\n",
    "\n",
    "adjacents.shape, adjacents_pub.shape, adjacents_pri.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(vocab):\n",
    "    \"\"\"One hot encoder\"\"\"\n",
    "    mapping = {}\n",
    "    n = len(vocab)\n",
    "    for i, s in enumerate(vocab):\n",
    "        mapping[s] = [0] * n\n",
    "        mapping[s][i] = 1\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def get_input(train):\n",
    "    \"\"\"Get node features, which is one hot encoded\"\"\"\n",
    "    vocab = [\"A\", \"U\", \"G\", \"C\"]\n",
    "    encoder = one_hot_encoder(vocab)\n",
    "    X_node = np.stack(\n",
    "        train[\"sequence\"].apply(\n",
    "            lambda sequence: list(map(lambda base: encoder[base], sequence))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    vocab = [\"S\", \"M\", \"I\", \"B\", \"H\", \"E\", \"X\"]\n",
    "    encoder = one_hot_encoder(vocab)\n",
    "    X_loop = np.stack(\n",
    "        train[\"predicted_loop_type\"].apply(\n",
    "            lambda string: list(map(lambda char: encoder[char], string))\n",
    "        )\n",
    "    )\n",
    "\n",
    "   \n",
    "    # vocab = [\".\", \"(\", \")\"]\n",
    "    # encoder = one_hot_encoder(vocab)\n",
    "    # X_structure = np.stack(\n",
    "    #     train[\"structure\"].apply(\n",
    "    #         lambda structure: list(map(lambda base: encoder[base], structure))\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    X_node = np.concatenate([X_node, X_loop], axis=2)\n",
    "\n",
    "    # interaction\n",
    "    a = np.sum(\n",
    "        X_node * (2 ** np.arange(X_node.shape[2])[None, None, :]),\n",
    "        axis=2,\n",
    "    )\n",
    "\n",
    "    vocab = sorted(set(a.flatten()))\n",
    "    print(vocab)\n",
    "\n",
    "    ohes = []\n",
    "    for v in vocab:\n",
    "        ohes.append(a == v)\n",
    "\n",
    "    ohes = np.stack(ohes, axis=2)\n",
    "    X_node = np.concatenate([X_node, ohes], axis=2).astype(np.float32)\n",
    "    print(X_node.shape)\n",
    "    return X_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(2096, 107, 39)\n",
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(629, 107, 39)\n",
      "[17, 18, 20, 24, 33, 34, 36, 40, 65, 66, 68, 72, 129, 130, 132, 136, 257, 258, 260, 264, 513, 514, 516, 520, 1025, 1026, 1028, 1032]\n",
      "(3005, 130, 39)\n"
     ]
    }
   ],
   "source": [
    "X_node = get_input(train)\n",
    "X_node_pub = get_input(test_pub)\n",
    "X_node_pri = get_input(test_pri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 16:26:50.450401: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-15 16:26:50.642189: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-15 16:26:50.642224: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-15 16:26:50.675194: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-15 16:26:50.744729: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-15 16:26:51.437420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, backend, Model, Input, optimizers\n",
    "from keras.layers import (\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    Permute,\n",
    "    Lambda,\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Add,\n",
    "    LayerNormalization,\n",
    "    Dropout,\n",
    "    LeakyReLU,\n",
    "    SpatialDropout1D\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcrmse(y_test, y_pred, seq_len_target=seq_len_target):\n",
    "    \"\"\"Calculate mcrmse score by using numpy\"\"\"\n",
    "    y_test = y_test[:, :seq_len_target]\n",
    "    y_pred = y_pred[:, :seq_len_target]\n",
    "\n",
    "    score = np.mean(\n",
    "        np.sqrt(\n",
    "            np.mean(\n",
    "                np.mean((y_pred - y_test) ** 2, axis=1),\n",
    "                axis=0,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def mcrmse_loss(y_test, y_pred, seq_len_target=seq_len_target):\n",
    "    \"\"\"Calculate mcrmse loss by using tf\"\"\"\n",
    "    y_test = y_test[:, :seq_len_target]\n",
    "    y_pred = y_pred[:, :seq_len_target]\n",
    "\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.sqrt(\n",
    "            tf.reduce_mean(\n",
    "                tf.reduce_mean((y_test - y_pred) ** 2, axis=1),\n",
    "                axis=0,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def attention(x_inner, x_outer, n_factor, dropout):\n",
    "    x_Q = Conv1D(\n",
    "        n_factor,\n",
    "        1,\n",
    "        activation=\"linear\",\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"glorot_uniform\",\n",
    "    )(x_inner)\n",
    "\n",
    "    x_K = Conv1D(\n",
    "        n_factor,\n",
    "        1,\n",
    "        activation=\"linear\",\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"glorot_uniform\",\n",
    "    )(x_outer)\n",
    "\n",
    "    x_V = Conv1D(\n",
    "        n_factor,\n",
    "        1,\n",
    "        activation=\"linear\",\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"glorot_uniform\",\n",
    "    )(x_outer)\n",
    "\n",
    "    x_KT = Permute((2, 1))(x_K)\n",
    "    res = Lambda(lambda c: backend.batch_dot(c[0], c[1]) / np.sqrt(n_factor))(\n",
    "        [x_Q, x_KT]\n",
    "    )\n",
    "\n",
    "    # res = tf.expand_dims(res, axis=3)\n",
    "    # res = Conv2D(16, 3, 1, padding=\"same\", activation=\"relu\")(res)\n",
    "    # res = Conv2D(1, 3, 1, padding=\"same\", activation=\"relu\")(res)\n",
    "    # res = tf.squeeze(res, axis=3)\n",
    "\n",
    "    att = Lambda(lambda c: backend.softmax(c, axis=-1))(res)\n",
    "    att = Lambda(lambda c: backend.batch_dot(c[0], c[1]))([att, x_V])\n",
    "    return att\n",
    "\n",
    "\n",
    "def multi_head_attention(x, y, n_factor, n_head, dropout):\n",
    "    if n_head == 1:\n",
    "        att = attention(x, y, n_factor, dropout)\n",
    "    else:\n",
    "        n_factor_head = n_factor // n_head\n",
    "        heads = [attention(x, y, n_factor_head, dropout) for i in range(n_head)]\n",
    "        att = Concatenate()(heads)\n",
    "        att = Dense(\n",
    "            n_factor,\n",
    "            kernel_initializer=\"glorot_uniform\",\n",
    "            bias_initializer=\"glorot_uniform\",\n",
    "        )(att)\n",
    "\n",
    "    x = Add()([x, att])\n",
    "    x = LayerNormalization()(x)\n",
    "    if dropout > 0:\n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def res(x, unit, kernel=3, rate=0.1):\n",
    "    h = Conv1D(unit, kernel, 1, padding=\"same\", activation=None)(x)\n",
    "    h = LayerNormalization()(h)\n",
    "    h = LeakyReLU()(h)\n",
    "    h = Dropout(rate)(h)\n",
    "    return Add()([x, h])\n",
    "\n",
    "\n",
    "def forward(x, unit, kernel=3, rate=0.1):\n",
    "    # h = Dense(unit, None)(x)\n",
    "    h = Conv1D(unit, kernel, 1, padding=\"same\", activation=None)(x)\n",
    "    h = LayerNormalization()(h)\n",
    "    h = Dropout(rate)(h)\n",
    "\n",
    "    # h = tf.keras.activations.swish(h)\n",
    "    h = LeakyReLU()(h)\n",
    "    h = res(h, unit, kernel, rate)\n",
    "    return h\n",
    "\n",
    "\n",
    "def adj_attention(x, adj, unit, n=2, rate=0.1):\n",
    "    x_a = x\n",
    "    x_as = []\n",
    "    for i in range(n):\n",
    "        x_a = forward(x_a, unit)\n",
    "        x_a = tf.matmul(adj, x_a)  # aggregate neighborhoods\n",
    "        x_as.append(x_a)\n",
    "\n",
    "    if n == 1:\n",
    "        x_a = x_as[0]\n",
    "    else:\n",
    "        x_a = Concatenate()(x_as)\n",
    "\n",
    "    x_a = forward(x_a, unit)\n",
    "    return x_a\n",
    "\n",
    "\n",
    "def get_optimizer(optim=\"Adam\"):\n",
    "    if optim == \"Adam\":\n",
    "        optimizer = optimizers.Adam()\n",
    "    elif optim == \"SGD\":\n",
    "        optimizer = optimizers.SGD(0.05, momentum=0.9, nesterov=True)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def get_base(config):\n",
    "    \"\"\"Base model architecture.\n",
    "    node, adj -> middle feature\"\"\"\n",
    "    node = Input(shape=(None, X_node.shape[2]), name=\"node\")\n",
    "    adj = Input(shape=(None, None, adjacents.shape[3]), name=\"adj\")\n",
    "\n",
    "    adj_learned = Dense(1, \"relu\")(adj)\n",
    "    adj_all = Concatenate(axis=3)([adj, adj_learned])\n",
    "\n",
    "    xs = []\n",
    "    xs.append(node)\n",
    "    x1 = forward(node, 128, kernel=3, rate=0.0)\n",
    "    x2 = forward(x1, 64, kernel=6, rate=0.0)\n",
    "    x3 = forward(x2, 32, kernel=15, rate=0.0)\n",
    "    x4 = forward(x3, 16, kernel=30, rate=0.0)\n",
    "    x = Concatenate()([x1, x2, x3, x4])\n",
    "\n",
    "    for unit in [64, 32]:\n",
    "        x_as = []\n",
    "        for i in range(adj_all.shape[3]):\n",
    "            x_a = adj_attention(x, adj_all[:, :, :, i], unit, rate=0.0)\n",
    "            x_as.append(x_a)\n",
    "\n",
    "        x_c = forward(x, unit, kernel=30)\n",
    "\n",
    "        x = Concatenate()(x_as + [x_c])\n",
    "        x = forward(x, unit)\n",
    "        x = multi_head_attention(x, x, unit, 4, 0.0)\n",
    "        xs.append(x)\n",
    "\n",
    "    x = Concatenate()(xs)\n",
    "    model = Model(inputs=[node, adj], outputs=[x])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ae_model(base, config):\n",
    "    \"\"\"Denoising auto encoder part.\\n\n",
    "    node, adj -> middle feature -> node\"\"\"\n",
    "    node = Input(shape=(None, X_node.shape[2]), name=\"node\")\n",
    "    adj = Input(shape=(None, None, adjacents.shape[3]), name=\"adj\")\n",
    "\n",
    "    x = base([SpatialDropout1D(0.3)(node), adj])\n",
    "    x = forward(x, 64, rate=0.3)\n",
    "    p = Dense(X_node.shape[2], \"sigmoid\")(x)\n",
    "\n",
    "    loss = -tf.reduce_mean(\n",
    "        20 * node * tf.math.log(p + 1e-4) + (1 - node) * tf.math.log(1 - p + 1e-4)\n",
    "    )\n",
    "    model = Model(inputs=[node, adj], outputs=[loss])\n",
    "\n",
    "    optim = get_optimizer(\"Adam\")\n",
    "    model.compile(optimizer=optim, loss=lambda t, y: y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(base, config):\n",
    "    \"\"\"Regression part\\n\n",
    "    node, adj -> middle feature -> prediction of targets\"\"\"\n",
    "    node = Input(shape=(None, X_node.shape[2]), name=\"node\")\n",
    "    adj = Input(shape=(None, None, adjacents.shape[3]), name=\"adj\")\n",
    "\n",
    "    x = base([node, adj])\n",
    "    x = forward(x, 128, rate=0.4)\n",
    "    x = Dense(5, None)(x)\n",
    "\n",
    "    model = Model(inputs=[node, adj], outputs=[x])\n",
    "\n",
    "    optim = get_optimizer()\n",
    "    model.compile(optimizer=optim, loss=mcrmse_loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----0-----\n",
      "--- Train ---\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 42s 112ms/step - loss: 0.9235\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 7s 107ms/step - loss: 0.3501\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 7s 107ms/step - loss: 0.1807\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 7s 108ms/step - loss: 0.1178\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 7s 108ms/step - loss: 0.0880\n",
      "--- Public ---\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 6s 332ms/step - loss: 0.0725\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 2s 107ms/step - loss: 0.0730\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 2s 107ms/step - loss: 0.0667\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 2s 107ms/step - loss: 0.0612\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 2s 107ms/step - loss: 0.0562\n",
      "--- Private ---\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train denoising auto encoder model using all data\n",
    "config = {}\n",
    "\n",
    "if ae_epochs > 0:\n",
    "    base = get_base(config)\n",
    "    ae_model = get_ae_model(base, config)\n",
    "\n",
    "    # TODO: simultaneous train\n",
    "    for i in range(ae_epochs // ae_epochs_each):\n",
    "        print(f\"-----{i}-----\")\n",
    "        print(\"--- Train ---\")\n",
    "        ae_model.fit(\n",
    "            [X_node, adjacents],\n",
    "            [X_node[:, 0]],\n",
    "            epochs=ae_epochs_each,\n",
    "            batch_size=ae_batch_size,\n",
    "        )\n",
    "\n",
    "        print(\"--- Public ---\")\n",
    "        ae_model.fit(\n",
    "            [X_node_pub, adjacents_pub],\n",
    "            [X_node_pub[:, 0]],\n",
    "            epochs=ae_epochs_each,\n",
    "            batch_size=ae_batch_size,\n",
    "        )\n",
    "\n",
    "        print(\"--- Private ---\")\n",
    "        ae_model.fit(\n",
    "            [X_node_pri, adjacents_pri],\n",
    "            [X_node_pri[:, 0]],\n",
    "            epochs=ae_epochs_each,\n",
    "            batch_size=ae_batch_size,\n",
    "        )\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    print(\"***** Save AE model *****\")\n",
    "    base.save_weights(\"./base_ae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15 16:13:23.050812: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-15 16:13:23.074401: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-15 16:13:23.074448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-15 16:13:23.075127: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-15 16:13:23.079473: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-15 16:13:23.496187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-15 16:13:23.851024: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-15 16:13:23.868647: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
